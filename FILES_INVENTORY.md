# üì¶ Invent√°rio de Arquivos - Projeto Completo

## üìÅ Estrutura de Documenta√ß√£o Criada

### 1. Documentos Principais

| Arquivo | Tipo | Finalidade | P√∫blico-Alvo |
|---------|------|------------|--------------|
| **README.md** | Guia | Vis√£o geral e quickstart do projeto | Desenvolvedores |
| **RESULTS.md** | An√°lise | Resultados detalhados e t√©cnicas aplicadas | Avaliadores t√©cnicos |
| **EXECUTIVE_SUMMARY.md** | Sum√°rio | Resumo executivo para apresenta√ß√£o | Stakeholders |
| **TECHNICAL_EVIDENCE.md** | Evid√™ncias | Logs e valida√ß√µes t√©cnicas | Auditoria/QA |
| **FILES_INVENTORY.md** | Invent√°rio | Este arquivo - lista todos os arquivos | Refer√™ncia |

---

### 2. C√≥digo Fonte Principal

```
src/
‚îú‚îÄ‚îÄ evaluate.py          # Script principal de avalia√ß√£o (10 casos)
‚îú‚îÄ‚îÄ push_prompts.py      # Push para LangSmith Hub
‚îú‚îÄ‚îÄ pull_prompts.py      # Pull do Hub
‚îú‚îÄ‚îÄ metrics.py           # M√©tricas LLM-as-Judge (5 m√©tricas)
‚îî‚îÄ‚îÄ utils.py             # Fun√ß√µes auxiliares (load_yaml, get_llm, etc)
```

**Descri√ß√£o:**
- **evaluate.py:** Avalia√ß√£o oficial com 10 casos do dataset
- **metrics.py:** Implementa√ß√£o de F1-Score, Clarity, Precision, Helpfulness, Correctness
- **utils.py:** Carregamento de configs, inicializa√ß√£o de LLMs, formata√ß√£o

---

**Descri√ß√£o:**

#### evaluate_quick.py (RECOMENDADO)
- **Casos:** 5 casos cr√≠ticos (#2, #4, #5, #6, #9)
- **Rodadas:** 3 independentes
- **Tempo:** ~3 minutos
- **Sa√≠da:** Estat√≠sticas agregadas (m√©dia, min, max, desvio)
- **Uso:** `python evaluate_quick.py`

#### diagnose_worst_cases.py (DIAGN√ìSTICO)
- **Casos:** 2 piores (#4, #5)
- **Sa√≠da:** Compara√ß√£o linha por linha (output vs refer√™ncia)
- **Tempo:** ~1 minuto
- **Uso:** `python diagnose_worst_cases.py`

#### diagnose_failures.py (COMPLETO)
- **Casos:** 5 casos problem√°ticos
- **Sa√≠da:** An√°lise detalhada com m√©tricas e diferen√ßas
- **Tempo:** ~3 minutos
- **Uso:** `python diagnose_failures.py`

---

### 4. Prompts

```
prompts/
‚îî‚îÄ‚îÄ bug_to_user_story_v2.yml    # ‚≠ê Prompt v4.0 otimizado (395 linhas)
```

**Estrutura do Prompt:**
- üé≠ Role Prompting (PM S√™nior emp√°tico)
- ‚ù§Ô∏è Emotional Priming (ativa√ß√£o de empatia)
- üß† Chain of Thought (6 passos)
- üìä Rubric-based Prompting (5 dimens√µes)
- üìö Few-Shot Learning (7 exemplos)
- ‚ùå‚úÖ Negative Examples (contrastes)
- üìã Regras Anti-Alucina√ß√£o (6 regras)

---

### 5. Dataset de Avalia√ß√£o

```
datasets/
‚îî‚îÄ‚îÄ bug_to_user_story.jsonl     # 15 exemplos (bug + refer√™ncia)
```

**Formato:**
```json
{
  "inputs": {"bug_report": "..."},
  "outputs": {"reference": "..."},
  "metadata": {"domain": "...", "type": "...", "complexity": "..."}
}
```

**Casos por Complexidade:**
- Simples: 7 casos
- M√©dio: 6 casos
- Complexo: 2 casos

---

### 6. Testes Unit√°rios

```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ test_prompts.py             # Valida√ß√£o de estrutura YAML
```

**Testes:**
- ‚úÖ Estrutura YAML v√°lida
- ‚úÖ Campos obrigat√≥rios presentes
- ‚úÖ T√©cnicas declaradas corretamente
- ‚úÖ Vers√£o e metadados

**Uso:** `pytest tests/ -v`

---

### 7. Configura√ß√£o

```
./
‚îú‚îÄ‚îÄ .env.example                # Template de configura√ß√£o
‚îú‚îÄ‚îÄ .env                        # Configura√ß√£o local (gitignored)
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias Python
‚îî‚îÄ‚îÄ .gitignore                  # Arquivos ignorados
```

**Vari√°veis de Ambiente (.env):**
```bash
OPENAI_API_KEY=sk-...
LANGSMITH_API_KEY=lsv2_pt_...
LANGCHAIN_PROJECT=prompt-optimization-challenge-resolved
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o
EVAL_MODEL=gpt-4o
```

---

## üìä Mapa de Fluxo

### Fluxo de Desenvolvimento

```mermaid
graph TD
    A[Editar prompt YAML] --> B[Validar estrutura]
    B --> C{V√°lido?}
    C -->|N√£o| A
    C -->|Sim| D[Push para LangSmith]
    D --> E[Avaliar casos cr√≠ticos]
    E --> F{M√©dia >= 0.9?}
    F -->|N√£o| G[Diagnosticar problemas]
    G --> A
    F -->|Sim| H[Avalia√ß√£o completa]
    H --> I[Documentar resultados]
```

### Fluxo de Valida√ß√£o

```mermaid
graph TD
    A[evaluate_quick.py] --> B[3 rodadas x 5 casos]
    B --> C[Calcular estat√≠sticas]
    C --> D{M√©dia >= 0.9?}
    D -->|Sim| E[‚úÖ APROVADO]
    D -->|N√£o| F[diagnose_worst_cases.py]
    F --> G[Comparar linha por linha]
    G --> H[Identificar diferen√ßas]
    H --> I[Ajustar prompt]
```

---

## üéØ Guia R√°pido: Quando Usar Cada Arquivo

### Para Desenvolver

| Tarefa | Arquivo | Comando |
|--------|---------|---------|
| Editar prompt | `prompts/bug_to_user_story_v2.yml` | Editor |
| Push para Hub | `src/push_prompts.py` | `python src/push_prompts.py` |

### Para Avaliar

| Tarefa | Arquivo | Comando | Tempo |
|--------|---------|---------|-------|
| Avalia√ß√£o completa | `src/evaluate.py` | `python src/evaluate.py` | ~5 min |

### Para Documentar

| Tarefa | Arquivo | Finalidade |
|--------|---------|------------|
| Apresentar resultados | `EXECUTIVE_SUMMARY.md` | Sum√°rio executivo |
| Documentar t√©cnicas | `RESULTS.md` | An√°lise completa |
| Mostrar evid√™ncias | `TECHNICAL_EVIDENCE.md` | Logs e valida√ß√µes |
| Guia de uso | `README.md` | Quickstart |

---

## üìà Hist√≥rico de Vers√µes

### v4.0 (Atual) - 2026-02-15
- ‚úÖ 6 t√©cnicas avan√ßadas implementadas
- ‚úÖ M√©dia 0.9764 (>= 0.9)
- ‚úÖ Scripts de teste criados
- ‚úÖ Documenta√ß√£o completa

**Arquivos adicionados:**
- `RESULTS.md`
- `EXECUTIVE_SUMMARY.md`
- `TECHNICAL_EVIDENCE.md`
- `FILES_INVENTORY.md`

### v3.1 - 2026-02-15
- Ajuste cir√∫rgico para bugs simples
- M√©dia 0.8679 (< 0.9)

### v3.0 - 2026-02-14
- Chain of Thought
- 7 exemplos
- Regras anti-hallucination

---

## üîó Links Externos

### LangSmith

- **Prompt Hub:** https://smith.langchain.com/prompts/bug_to_user_story_v2/032a9885
- **Vers√£o atual:** v4.0 (commit 032a9885)
- **P√∫blico:** Sim
- **Owner:** Configurado no .env

### Reposit√≥rio

```bash
# Clone
git clone <repository-url>

# Branch principal
main

# Commit atual
<git-hash>
```

---

## üìù Checklist de Entrega

### C√≥digo
- [x] Prompt v4.0 otimizado
- [x] Scripts de avalia√ß√£o funcionais
- [x] Testes unit√°rios validados
- [x] Depend√™ncias documentadas

### Documenta√ß√£o
- [x] README.md (guia de uso)
- [x] RESULTS.md (an√°lise completa)
- [x] EXECUTIVE_SUMMARY.md (sum√°rio executivo)
- [x] TECHNICAL_EVIDENCE.md (evid√™ncias t√©cnicas)
- [x] FILES_INVENTORY.md (invent√°rio)

### Valida√ß√£o
- [x] M√©dia >= 0.9 atingida
- [x] Testes em m√∫ltiplas rodadas
- [x] Outputs validados linha por linha
- [x] Variabilidade medida e documentada

### Deploy
- [x] Prompt publicado no LangSmith Hub
- [x] Vers√£o v4.0 taggeada
- [x] Changelog atualizado

---

## üíæ Backup e Arquivamento

### Arquivos Cr√≠ticos (Backup Essencial)

```
‚úÖ prompts/bug_to_user_story_v2.yml    (Prompt principal)
‚úÖ datasets/bug_to_user_story.jsonl    (Dataset de teste)
‚úÖ .env                                 (Credenciais - local only)
‚úÖ RESULTS.md                           (Resultados finais)
```

### Arquivos Gerados (Podem ser Recriados)

```
‚ö†Ô∏è __pycache__/                       (Cache Python)
‚ö†Ô∏è .pytest_cache/                     (Cache pytest)
‚ö†Ô∏è venv/                              (Ambiente virtual)
```

---

## üõ†Ô∏è Manuten√ß√£o

### Atualiza√ß√£o de Depend√™ncias

```bash
# Ver vers√µes atuais
pip list

# Atualizar requirements.txt
pip freeze > requirements.txt

# Verificar vulnerabilidades
pip audit
```

### Sincroniza√ß√£o com LangSmith

```bash
# Pull da vers√£o mais recente
python src/pull_prompts.py

# Push de altera√ß√µes locais
python src/push_prompts.py
```

---

## üìû Suporte

### Problemas Comuns

| Problema | Solu√ß√£o | Arquivo |
|----------|---------|---------|
| Rate limit OpenAI | Use `evaluate_quick.py` | `evaluate_quick.py` |
| F1-Score baixo | Execute diagn√≥stico | `diagnose_worst_cases.py` |
| Push falha | Verifique `.env` | `.env` |
| Testes falham | Valide YAML | `tests/test_prompts.py` |

---

## üìö Leitura Adicional

### Dentro do Projeto
1. [README.md](README.md) - Come√ße aqui
2. [RESULTS.md](RESULTS.md) - An√°lise detalhada
3. [EXECUTIVE_SUMMARY.md](EXECUTIVE_SUMMARY.md) - Sum√°rio
4. [TECHNICAL_EVIDENCE.md](TECHNICAL_EVIDENCE.md) - Evid√™ncias

### Externos
- [LangChain Docs](https://python.langchain.com/docs/)
- [LangSmith Docs](https://docs.smith.langchain.com/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

---

**√öltima atualiza√ß√£o:** 2026-02-15
**Vers√£o:** v4.0
**Status:** ‚úÖ Completo
